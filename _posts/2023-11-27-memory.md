---
title: Memory 관련 정리
date: 2023-11-27 00:00 +09:00
categories: ['cs', 'memory']
tags:
  - 'memory'
image:
  path: bird.jpeg
  alt: ''
mermaid: true
---

<!-- @format -->

## 기존 메모리 구조

![image](https://gist.github.com/assets/30681841/8fb26fb6-3d27-455f-bf4c-1f853e0621ba)

CPU 에서 내린 명령을 메모리에 적재하고, 다시 CPU 로 보내는 전통적인 방법이다. 기술이 발달하며 n개의 프로세스를 동시에 실행하는
프로그램이 나오면서 메모리가 부족한 상황이 생겼고, 이를 해결하기 위해서 가상 메모리 기술이 등장했다.

## 가상 메모리

![image](https://gist.github.com/assets/30681841/9e0ec3ab-c485-439a-aadd-b2ebc7e6dc71)

한줄요약 : 부족한 메모리 확보를 위해 HDD, SSD 같은 `저장 장치`를 _메모리의 일부_ 로 사용하는 기술이다.

### Page Table

![image](https://gist.github.com/assets/30681841/3616dd0f-f69a-42f5-9cc6-4dd8ce69c2e3)

저장 장치에 올라간 작업 단위를 `Page` 라고 하고, 어떤 작업인지 참조하기 위해 `Page Table` 을 OS 에서 관리한다. Valid Bit 를 통해서 메모리에
올라가 있는지 아닌지 여부를 판단한다.

> 저장장치에 작업을 분담시키기 위해서 프로세스를 최소한의 단위로 잘게 쪼갠 걸 Page 라고 한다. <br>
> 실제 메모리에서는 Frame 이라고 부른다.

저장장치와 작업부하를 분담하며 당장 필요한 Page 만 메모리에 올리기 때문에 효율적이다.

![image](https://gist.github.com/assets/30681841/a1d921ab-0636-4461-a121-b4916c2ffb98)

이러한 과정을 담당하는 하드웨어가 있는데 이를 `MMU (Memory Management Unit)` 이라고 부른다.

```mermaid
flowchart LR
  Program --> MMU
  MMU --> Memeory
```

`MMU` 를 통해 `가상 주소`를 `물리 메모리 주소`로 **_변환_**할 수 있다.

### Page Fault

CPU 가 프로그램을 실행할 때, 페이지가 물리적 메모리에 아직 들어가지 않은 경우도 생기는데 이를 `Page Fault` 라고 한다. **예외** 가 발생하는 상황인데,
이 때 OS 는 프로그램을 중단시키는 것이 아닌, `MMU` 를 통해 추가 메모리를 확보하고, 스택 공간을 늘린다.

## 가상 메모리

`Page Fault` 상황을 막기 위해 가상의 메모리를 추가적으로 확보하는 메커니즘을 유용하게 써먹는 것이 가상 메모리 시스템이다.

만약 물리 메모리보다 더 큰 메모리를 요청받은 경우 OS 는 이를 어떻게 처리할까?

- 현재 필요하지 않은 메모리 page 를 저장장치로 옮긴다
  - 이를 `swap out` 이라고 한다.
  - `swap out` 된 page 에 프로그램이 접근하면 운영체제는 필요한 메모리를 확보한 뒤,
    - 요청받은 page 를 다시 메모리로 부른다.
    - 이를 `swap in` 이라고 한다.

이런 과정을 `swapping` 이라고 부르는데, 이는 시스템 성능의 저하를 불러 일으킨다. 성능 저하를 막기 위한 여러 방법이 사용되는데, 그중에 대표적인 것이
LRU 알고리즘이다. 최근에 가장 자주 사용된 page 는 물리 메모리에 가만히 내버려두고, 가장 덜 사용한 page 를 swap-out 하는 방식이다.

## I/O 의 개입

MMU 를 이용해서 갑자기 프로세스가 종료되는 일 없도록 안정적인 OS 를 작동시킬 수 있다고 생각했지만, I/O 과정이 개입되는 순간 균형이 깨진다.

CPU 는 trap 이나 system call 이라고 부르는 특별한 명령어를 통해서 user 모드에서 실행 중인 프로그램이 system 모드 프로그램에 요청을 보낼 수 있도록 하는 하드웨어가 존재한다.

## 메모리 계층과 성능

가상 메모리, 그리고 스와핑은 메모리 계층이라는 개념을 이끌어냈다.

프로세서에는 register 라는 비싸고 굉장히 빠른 메모리가 들어있다. 거듭된 발전에도 register 가 전체 메모리에서 차지하는 비율은 점점 줄어들었다.
다만, RAM 이라고 불리는 주 메모리와 통신하는데 CPU 보다 10배 정도 느리다.

CPU 가 RAM 과 통신하며 온갖 명령을 수행하는데, CPU 가 10배 빠르다면, 싱크가 안맞는 것은 당연한 일이다. 따라서 싱크를 맞추기 위해 `cache` 라는 하드웨어를 CPU 에 추가했다.

- 분기가 없는 경우 프로그램 메모리는 순서대로 읽힌다.
- 필요한 데이터가 한데 모여 있는 경우가 많다.

위 2가지 현상을 활용하여 시스템 성능을 높인다.

`CPU Memory Controller` 라는 하드웨어는 메모리에서 연속된 `열` 에 있는 데이터를 한꺼번에 가져온다.

- `cache` 에 데이터가 없어서 RAM 을 읽어야 하는 경우
  - `cache miss`
- CPU 가 원하는 내용을 cache 에서 찾은 경우
  - `cache hit`

CPU 에 달려있는 `cache` 메모리에 계층이 존재한다.

![image](https://gist.github.com/assets/30681841/c8fbddd9-a071-493c-ba8b-3984dfcfcf00)

정확한 데이터를 가져오기 위해서 `prefetch` 를 통해 cache 를 준비시키기 위해, 조건 분기 명령어의 결과를 예측하는 `분기 예측 회로`를 통해
성능을 향상시킬 수 있다. 거기에 `순서를 벗어나는 실행(out-of-order-execution)` 을 담당하는 회로도 존재한다.

cache 의 일관성을 유지하는 것은 굉장히 어려운 일이고, 이를 관리하기 위한 하드웨어가 많이 생겨났다.
(\* CPU 의 cache 는 너무 빠르기 때문에 감히 일개 소프트웨어가 관리할 수 없다고 한다.)

### coprocessor

요약: 반복적이고 단순한 연산을 위한 프로세서를 추가한다.

일부 코프로세서는 데이터의 복사 만을 담당하는데, 이를 직접 메모리 접근 (Direct Memory Access) 라고 한다.

## 메모리상의 데이터 배치

실행하기 전에는 크기를 파악할 수 없는 데이터를 동적 데이터 라고 부른다. 이는 Heap 영역에 쌓이게 되고, 정적 데이터는 Stack 영역에 쌓인다.

## 프로그램 실행

> 라이브러리란?

프로그래머가 편의를 위해서 재사용해서 사용하기 좋은 함수를 모아둔 것을 라이브러리라고 부른다. 다른 프로그램에서 동일한 메모리에 접근해서 사용하기 위해 Linker 라는 프로그램을 사용해야 한다.
프로그래머들은 동적 링크를 발명했고, MMU 를 통해 완전히 다른 프로그램이 동일한 라이브러리를 공유할 수 있게 되었다.

프로그램에는 진입점이 있는데, 진입점의 명령어가 실행되기 이전에 runtime 라이브러리가 먼저 실행된다. 이 런타임 라이브러리가 스택, 힙 영역을 설정한다.

## 출처

- [https://velog.io/@jiseong/OS-%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC%EC%99%80-%ED%8E%98%EC%9D%B4%EC%A7%80%ED%8F%B4%ED%8A%B8-gyq8tftz](https://velog.io/@jiseong/OS-%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC%EC%99%80-%ED%8E%98%EC%9D%B4%EC%A7%80%ED%8F%B4%ED%8A%B8-gyq8tftz)

![image](https://gist.github.com/assets/30681841/6874e76c-8e45-4945-a540-f831a6aa48d2)
